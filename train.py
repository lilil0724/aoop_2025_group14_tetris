import cma
import numpy as np
import pickle
import multiprocessing as mp
import os
import time
from tetris_env import TetrisEnv

# --- é€²åŒ–åƒæ•¸ ---
POPULATION_SIZE = 16   # æ¯ä¸€ä»£æœ‰ 16 å€‹ AI åƒè³½
GENERATIONS = 100      # ç¸½å…±é€²åŒ– 100 ä»£
GAMES_PER_AGENT = 5    # æ¯å€‹ AI ç© 5 å ´å–å¹³å‡ (æ¸›å°‘é‹æ°£æˆåˆ†)
MAX_STEPS = 5000       # æ¯å ´æœ€å¤šç©å¹¾æ­¥ (é¿å…ç„¡é™ç©)

# åˆå§‹æ¬Šé‡çŒœæ¸¬ (æ ¹æ“šæ–‡ç»ç¶“é©—):
# [ç¸½é«˜åº¦, æ¶ˆè¡Œæ•¸, ç©ºæ´æ•¸, ç²—ç³™åº¦]
# æ³¨æ„ï¼šCMA-ES æ˜¯æ±‚ "æœ€å°å€¼"ï¼Œæ‰€ä»¥æˆ‘å€‘è¦ "æœ€å¤§åŒ–åˆ†æ•¸" = "æœ€å°åŒ–è² åˆ†"
# æˆ‘å€‘å¸Œæœ›ï¼šé«˜åº¦ä½(-), æ¶ˆè¡Œå¤š(+), ç©ºæ´å°‘(-), ç²—ç³™å°‘(-)
# åˆå§‹ç¨®å­ï¼š[-0.5, 0.76, -0.36, -0.18] (é€™æ˜¯ Pierre Dellacherie ç®—æ³•çš„è®Šé«”)
# ä¿®æ”¹ INITIAL_WEIGHTS
# Dellacherie ç¶“é©—å€¼åƒè€ƒï¼š
# Height: -1
# Row Trans: -1
# Col Trans: -1
# Holes: -4  (ç©ºæ´æ‡²ç½°æœ€é‡)
# Wells: -1
INITIAL_WEIGHTS = [-1.37156088, -2.23096415, -0.74890419, -3.87641746, -0.53129402, -0.36264025,
  0.04413783, -0.91904935]
INITIAL_SIGMA = 0.1    # çªè®Šå¹…åº¦

# --- è©•ä¼°å‡½æ•¸ (Worker) ---
def evaluate_agent(weights):
    env = TetrisEnv()
    total_lines = 0
    tetris_count = 0
    for _ in range(GAMES_PER_AGENT):
        state = env.reset() # state å·²ç¶“æ˜¯ [agg_height, row_trans, col_trans, holes, wells]
        done = False
        steps = 0
        
        while not done and steps < MAX_STEPS:
            steps += 1
            possible_next = env.get_possible_next_states()
            
            if not possible_next: break
            
            best_score = -float('inf')
            best_action = None
            
            for action, features in possible_next.items():
                # features å·²ç¶“æ˜¯ 5 ç¶­å‘é‡
                # weights ä¹Ÿæ˜¯ 5 ç¶­å‘é‡
                score = np.dot(weights, features)
                
                if score > best_score:
                    best_score = score
                    best_action = action
            
            if best_action:
                _, done = env.step(best_action)
                if env.last_cleared_lines == 4: # éœ€åœ¨ env ä¸­è¨˜éŒ„ last_cleared_lines
                    tetris_count += 1
                elif env.last_cleared_lines == 3:
                    tetris_count += 0.7
                elif env.last_cleared_lines == 2:
                    tetris_count += 0.3
            else:
                break
        
        # æˆ‘å€‘å„ªåŒ–ç›®æ¨™æ˜¯ "æ¶ˆè¡Œæ•¸"
        total_lines += env.line_count
        
    avg_lines = total_lines / GAMES_PER_AGENT
    score = avg_lines + (tetris_count * 10)
    # CMA-ES æ±‚æœ€å°åŒ–ï¼Œæ‰€ä»¥å›å‚³è² çš„æ¶ˆè¡Œæ•¸
    # å¦‚æœä½ æ˜¯ç”¨ score ä¹Ÿå¯ä»¥ï¼Œä½† lines æ¯”è¼ƒç›´è§€
    return -score, avg_lines 


# --- ä¸»è¨“ç·´è¿´åœˆ ---
def train_evolution():
    # è¨­å®šå¤šé€²ç¨‹
    num_workers = mp.cpu_count() - 3
    pool = mp.Pool(num_workers)
    
    # åˆå§‹åŒ– CMA-ES
    es = cma.CMAEvolutionStrategy(INITIAL_WEIGHTS, INITIAL_SIGMA, {'popsize': POPULATION_SIZE})
    
    print(f"ğŸ§¬ é–‹å§‹é€²åŒ–è¨“ç·´... (Workers: {num_workers})")
    print(f"åˆå§‹æ¬Šé‡: {INITIAL_WEIGHTS}")
    
    best_ever_score = 0
    
    for gen in range(GENERATIONS):
        start_time = time.time()
        
        # 1. ç”Ÿå°å­© (Ask)
        solutions = es.ask()
        
        # 2. è€ƒè©¦ (Evaluate) - å¹³è¡Œè™•ç†
        # solutions æ˜¯ä¸€ç¾¤æ¬Šé‡å‘é‡
        results = pool.map(evaluate_agent, solutions)
        
        # è§£åŒ…çµæœ
        fitness_values = [r[0] for r in results] # è² åˆ† (çµ¦ CMA-ES ç”¨)
        lines_cleared = [r[1] for r in results]  # å¯¦éš›æ¶ˆè¡Œæ•¸ (çµ¦äººçœ‹)
        
        # 3. æ›´æ–°å®¶é•· (Tell)
        es.tell(solutions, fitness_values)
        es.logger.add()
        
        # 4. é¡¯ç¤ºé€²åº¦
        current_best_score = -min(fitness_values)
        avg_gen_score = -np.mean(fitness_values)
        max_lines = max(lines_cleared)
        
        if current_best_score > best_ever_score:
            best_ever_score = current_best_score
            # å­˜æª”
            best_weights = es.result.xbest
            with open("tetris_best_weights.pkl", "wb") as f:
                pickle.dump(best_weights, f)
            print(f"ğŸ’¾ æ–°ç´€éŒ„ï¼æ¬Šé‡å·²å„²å­˜ã€‚")
            
        print(f"Gen {gen+1} | Best: {current_best_score:.0f} | Avg: {avg_gen_score:.0f} | Max Lines: {max_lines:.1f} | Time: {time.time()-start_time:.1f}s")
        print(f"   Top Weights: {es.result.xbest}")
        
        es.disp()

    print("è¨“ç·´çµæŸï¼")
    pool.close()
    pool.join()

if __name__ == "__main__":
    # Windows å¿…é ˆ
    mp.set_start_method('spawn', force=True)
    train_evolution()
