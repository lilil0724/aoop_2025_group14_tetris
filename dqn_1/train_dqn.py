import os
import random
import copy
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from collections import deque
import config
import pieces
import shots
import Handler

# ==========================================
# 1. åƒæ•¸è¨­å®š
# ==========================================
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ”¥ Training on: {DEVICE}")

MAX_EPISODES = 30000        
EPS_START = 0.3         
EPS_END = 0.001          
EPS_DECAY_EPISODES = 26000

# ä¿®æ”¹ï¼šåŠ å¤§è¨˜æ†¶é«”ï¼Œç¸®å° Batch Size ä»¥ç©©å®šåˆæœŸå­¸ç¿’
MEMORY_SIZE = 30000        
BATCH_SIZE = 128
GAMMA = 0.95              
LR = 1e-4              # é‡æ–°è¨“ç·´å»ºè­°å…ˆç”¨è¼ƒå¤§çš„ LR (1e-3)ï¼Œä¹‹å¾Œå¾®èª¿å¯æ”¹ 1e-4

SAVE_PATH = 'tetris_dqn_new.pt' # å»ºè­°æ”¹åï¼Œé¿å…è®€åˆ°èˆŠçš„æ ¼å¼å ±éŒ¯

# ==========================================
# 2. è¼”åŠ©å‡½å¼
# ==========================================

# æ–°å¢ï¼šè¨ˆç®—å–®åˆ—é«˜åº¦çš„å°å·¥å…· (çµ¦çå‹µå‡½æ•¸ç”¨)
def get_column_height(board, col_idx):
    rows = config.rows
    for r in range(rows):
        if board[r][col_idx] == 2:
            return rows - r
    return 0

def get_raw_board_stats(board):
    rows, cols = config.rows, config.columns
    grid = np.array(board).reshape(rows, cols)
    
    heights = []
    for c in range(cols):
        col_data = grid[:, c]
        if np.any(col_data == 2): 
            h = rows - np.argmax(col_data == 2)
            heights.append(h)
        else:
            heights.append(0)
            
    max_height = max(heights)
    
    holes = 0
    for c in range(cols):
        block_found = False
        for r in range(rows):
            if grid[r][c] == 2:
                block_found = True
            elif block_found and grid[r][c] == 0:
                holes += 1
                
    return max_height, holes

# ==========================================
# 3. æ ¸å¿ƒç‰¹å¾µæå– (ä¿®æ­£ç‰ˆï¼š5 ç‰¹å¾µ)
# ==========================================
def get_nuno_features(board, lines_cleared):
    rows, cols = config.rows, config.columns
    grid = np.array(board).reshape(rows, cols)
    
    # --- 1. è¨ˆç®—æ¯è¡Œé«˜åº¦ (Heights) ---
    heights = []
    for c in range(cols):
        col_data = grid[:, c]
        if np.any(col_data == 2): 
            h = rows - np.argmax(col_data == 2)
            heights.append(h)
        else:
            heights.append(0)
            
    # --- 2. è¨ˆç®—æ·±äº• (Wells) [åŸæœ¬ç¼ºå°‘çš„!] ---
    wells = 0
    for c in range(cols):
        left_h = heights[c-1] if c > 0 else rows
        right_h = heights[c+1] if c < cols - 1 else rows
        my_h = heights[c]
        depth = min(left_h, right_h) - my_h
        if depth >= 2:
            wells += depth

    # --- 3. è¨ˆç®—å‘æ´ (Holes) ---
    holes_count = 0
    for c in range(cols):
        block_found = False
        for r in range(rows):
            if grid[r][c] == 2:
                block_found = True
            elif block_found and grid[r][c] == 0:
                holes_count += 1
                
    # --- 4. è¨ˆç®—è¡¨é¢å‡¹å‡¸ (Bumpiness) ---
    bump_sum = 0
    for i in range(cols - 1):
        bump_sum += abs(heights[i] - heights[i+1])

    # --- 5. æ­¸ä¸€åŒ– (Normalization) ---
    f_lines = float(lines_cleared) / 4.0
    f_holes = min(float(holes_count) / 20.0, 1.0)
    f_bumpiness = min(float(bump_sum) / 50.0, 1.0)
    f_height = min(float(sum(heights)) / 200.0, 1.0)
    f_wells = min(float(wells) / 20.0, 1.0) # æ–°å¢é€™å€‹

    # å›å‚³å®Œæ•´çš„ 5 å€‹ç‰¹å¾µ
    return np.array([f_lines, f_holes, f_bumpiness, f_height, f_wells], dtype=np.float32)

# ==========================================
# 4. æ¨¡å‹çµæ§‹ (ä¿®æ­£ç‰ˆï¼šè¼¸å…¥ 5)
# ==========================================
class NunoNet(nn.Module):
    def __init__(self):
        super().__init__()
        # ä¿®æ”¹ï¼šInput 5 features, Hidden layer 64
        self.net = nn.Sequential(
            nn.Linear(5, 64),  
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
        self._init_weights()
        
    def _init_weights(self):
        for m in self.net.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')
                nn.init.constant_(m.bias, 0)
        # æŠ€å·§ï¼šè®“æœ€å¾Œä¸€å±¤ Bias ç¨å¾®åæ­£ï¼Œé¼“å‹µæ´»è‘—
        with torch.no_grad():
             self.net[-1].bias.fill_(0.1)

    def forward(self, x):
        return self.net(x)

# ==========================================
# 5. è¨“ç·´ä¸»ç¨‹å¼
# ==========================================
def train():
    model = NunoNet().to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    criterion = nn.MSELoss()
    memory = deque(maxlen=MEMORY_SIZE)
    
    start_episode = 0
    # å˜—è©¦è¼‰å…¥èˆŠæª”ï¼Œå¦‚æœå½¢ç‹€ä¸å°(å ±éŒ¯)å°±å¾é ­é–‹å§‹
    if os.path.exists(SAVE_PATH):
        try:
            chk = torch.load(SAVE_PATH)
            model.load_state_dict(chk['model'])
            optimizer.load_state_dict(chk['optimizer'])
            start_episode = chk['episode'] + 1
            print(f"âœ… Loaded checkpoint from Episode {start_episode}")
        except Exception as e:
            print(f"âš ï¸ Load failed ({e}), starting NEW training session.")

    print(f"--- Starting Adaptive Strategy Training (Total: {MAX_EPISODES}) ---")
    
    def get_epsilon(ep):
        if ep > EPS_DECAY_EPISODES: return EPS_END
        decrease = (EPS_START - EPS_END) / EPS_DECAY_EPISODES
        return EPS_START - (decrease * ep)

    for episode in range(start_episode, MAX_EPISODES):
        shot = shots.Shot()
        piece = pieces.Piece(5, 0, random.choice(list(config.shapes.keys())))
        
        epsilon = get_epsilon(episode)
        
        step_count = 0
        total_reward = 0
        game_over = False
        
        while not game_over:
            legal_moves = []
            rots = len(config.shapes[piece.shape])
            if piece.shape == 'O': rots = 1
            elif piece.shape in ['S', 'Z', 'I']: rots = 2
            
            for rot in range(rots):
                t_piece = pieces.Piece(piece.x, piece.y, piece.shape)
                t_piece.rotation = rot
                for x in range(-2, config.columns + 1):
                    t_piece.x = x
                    if Handler.isValidPosition(shot, t_piece):
                        legal_moves.append((x, rot))
            
            if not legal_moves:
                game_over = True
                break
                
            candidates = [] 
            for action in legal_moves:
                s_sim = copy.deepcopy(shot)
                p_sim = copy.deepcopy(piece)
                p_sim.x, p_sim.rotation = action
                Handler.instantDrop(s_sim, p_sim)
                clears, _ = Handler.eliminateFilledRows(s_sim, p_sim)
                
                # === [ä¿®æ”¹é‡é»] å‹•æ…‹ç­–ç•¥èˆ‡çå‹µè¨ˆç®— ===
                
                # 1. å–å¾—ç›¤é¢åŸå§‹ç‹€æ…‹ (ç”¨æ–¼åˆ¤æ–·æ˜¯å¦å±éšª)
                sim_max_h, sim_holes = get_raw_board_stats(s_sim.status)
                
                # 2. å±éšªåˆ¤å®š
                is_dangerous = (sim_holes > 2) or (sim_max_h >= 7)
                
                r = 15.0 # åªè¦æ´»è‘—å°±æœ‰ 1 åˆ†
                
                if is_dangerous:
                    # === [ç­–ç•¥ A: ä¿å®ˆ/ææ…Œæ¨¡å¼] ===
                    if clears > 0:
                        r += clears * 20.0  # æœ‰æ¶ˆå°±å¥½
                    
                    # æ‡²ç½°ï¼šåœ¨å±éšªæ¨¡å¼ä¸‹ï¼Œå°ã€Œæ´ã€å’Œã€Œé«˜åº¦ã€é‡ç½°
                    r -= sim_holes * 1.5   
                    r -= sim_max_h * 0.8    
                    
                else:
                    # === [ç­–ç•¥ B: æ¿€é€²/è²ªå©ªæ¨¡å¼] ===
                    if clears > 0:
                        # æŒ‡æ•¸ç´šçå‹µï¼šæ¶ˆ4è¡Œ(Tetris) çµ¦æ¥µé«˜åˆ†
                        if clears == 4:
                            r += 300.0
                        else:
                            r += (clears ** 2) * config.columns
                    
                    # å®‰å…¨æ¨¡å¼ä¸‹ï¼Œç¨å¾®å®¹å¿æ·±äº• (ç‚ºäº† Tetris)
                    r -= sim_holes * 0.5 
                    r -= sim_max_h * 0.3    
                
                # é¡å¤–ï¼šåŠ ä¸Š Bumpiness (è¡¨é¢å‡¹å‡¸) æ‡²ç½°
                sim_bump = sum(abs(get_column_height(s_sim.status, i) - get_column_height(s_sim.status, i+1)) for i in range(config.columns - 1))
                r -= sim_bump * 0.5

                # 3. ç²å–ç‰¹å¾µ (é€™æ˜¯ä¿®æ­£å¾Œçš„ 5 ç‰¹å¾µç‰ˆæœ¬!)
                f = get_nuno_features(s_sim.status, clears)
                
                candidates.append((f, r, s_sim.status, action))

            # Epsilon-Greedy é¸æ“‡
            if random.random() < epsilon:
                chosen = random.choice(candidates)
            else:
                model.eval()
                with torch.no_grad():
                    feats = [c[0] for c in candidates]
                    b_f = torch.tensor(np.array(feats), dtype=torch.float32, device=DEVICE)
                    q_vals = model(b_f).squeeze(-1)
                    best_idx = torch.argmax(q_vals).item()
                chosen = candidates[best_idx]
                
            feat, reward, next_board_status, action = chosen
            
            next_piece = pieces.Piece(5, 0, random.choice(list(config.shapes.keys())))
            next_shot_obj = shots.Shot()
            next_shot_obj.status = next_board_status 
            
            # === [ä¿®æ”¹é‡é»] æ­»äº¡æ‡²ç½°åŠ é‡ ===
            if Handler.isDefeat(next_shot_obj, next_piece):
                reward = -1000.0   # è®“ AI æ¥µåº¦ææ‡¼æ­»äº¡
                game_over = True
                done = True
            else:
                done = False
                
            memory.append((feat, reward, done, next_board_status))
            
            shot = next_shot_obj
            piece = next_piece
            total_reward += reward
            step_count += 1
            
            if step_count > 5000: game_over = True 
            
            # è¨“ç·´æ­¥ (Experience Replay)
            if len(memory) >= BATCH_SIZE and step_count % 5 == 0: # åŠ å¿«è¨“ç·´é »ç‡
                batch = random.sample(memory, BATCH_SIZE)
                b_f, b_r, b_d, b_next_st = zip(*batch)
                
                t_f = torch.tensor(np.array(b_f), dtype=torch.float32, device=DEVICE)
                t_r = torch.tensor(b_r, dtype=torch.float32, device=DEVICE)
                t_d = torch.tensor(b_d, dtype=torch.float32, device=DEVICE)
                
                model.eval()
                with torch.no_grad():
                    next_feats = []
                    for st in b_next_st:
                        next_feats.append(get_nuno_features(st, 0)) # Next state é è¨­ clears=0
                    t_next_f = torch.tensor(np.array(next_feats), dtype=torch.float32, device=DEVICE)
                    q_next = model(t_next_f).squeeze(-1)
                
                target = t_r + GAMMA * q_next * (1 - t_d)
                
                model.train()
                q_pred = model(t_f).squeeze(-1)
                loss = criterion(q_pred, target)
                
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

        if episode % 50 == 0:
            print(f"Ep {episode} | Score: {total_reward:.1f} | Eps: {epsilon:.3f} | Steps: {step_count}")
            torch.save({
                'episode': episode,
                'model': model.state_dict(),
                'optimizer': optimizer.state_dict()
            }, SAVE_PATH)

if __name__ == '__main__':
    train()